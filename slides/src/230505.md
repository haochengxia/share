---
title: Group Meeting Share 23/05/05
separator: <!--s-->
verticalSeparator: <!--v-->
theme: simple
highlightTheme: github
css: custom.css
revealOptions:
    transition: 'slide'
    transitionSpeed: fast
    center: false
    slideNumber: "c/t"
    width: 1000
---

<div class="middle center">
<div style="width: 100%">

# Data-OOB (ICML '23)

<hr/>

<u>O</u>ut-<u>o</u>f-<u>b</u>ag Estimate as a Simple and Efficient Data Value

<font color="gray">Yongchan Kwon</font> (Columbia U) & <font color="gray">James Zou</font> (Stanford U)

<div style="text-align: right; margin-top: 1em;">
<p>2023.5.5&emsp;&emsp;&emsp;</p>
</div>

</div>
</div>

<!--s-->

<div class="middle center">
<div style="width: 100%">

# Part.1 Background

</div>
</div>

<!--v-->

## Downstream tasks of valuation

Many Shapley-based data valuation methods have shown promising results in various downstream tasks. 

- Data Cleaning, <font color="gray">i.e., recognize harmful/noisy/irrelevant data points</font>;
- Data Selection or Summarization, <font color="gray">e.g.,unbalanced scenario</font>;
- Data Pricing <font color="red">not only rank [less work]</font>;
- ...

<div style="text-align: left; margin-top: 0.5em;">
<img src="230505/sv_for_data_clean.png" width="40%" style="margin: 0 auto;">
<img src="230505/sv_for_data_select.png" width="50%" style="margin: 0 auto;">
</div>

<!--v-->

## Shortage of existing work

- General Data Shapley requires training a significant number of models;
- KNN-Shapley only for unweighted $k$-NN models;
- Improving sample efficiency still need heavy computational costs (small dataset $\le 1000$);
- Validation dataset for utility function is not always available;
- Shapley axiomsâ€™ relevance to machine learning applications is unclear;
- ...

<!--s-->

<div class="middle center">
<div style="width: 100%">

# Part.2 OOB method

</div>
</div>

<!--v-->

## Jackknife-after-Bootstrap

<font color="blue">**Bootstrap**</font>: resampling on original samples with replacement

Using resampled statistics from the original data can approximate the relationship between the original sample statistics and population statistics

<font color="blue">**Jackknife**</font>: leave one out

Generates multiple leave-one-out estimates by repeatedly deleting one observation from the original data.

<!--v-->

## Framework

<div class="mul-cols">
<div class="col">

<div style="text-align: left; margin-top: 0.5em;">
<img src="230505/oob.png" width="100%" style="margin: 0 auto;">
</div>
</div>

<div class="col">
Why validation dataset is not necessary?

Predicting over the training data!

Each weak leaner is a decision tree and $T(y_1, y_2) = \mathbb{1}( y_1 = y_2 )$.

$\frac{1}{n} \sum_{i=1}^{n} \frac{\sum_{b=1}^{B} \mathbb{1}(w_{b i}=0) T(y_{i}, f_{b}(x_{i}))}{\sum_{b=1}^{B} \mathbb{1}(w_{b i}=0)}$

</div>
</div>

<!--s-->

<div class="middle center">
<div style="width: 100%">

# Part.3 Experiments

</div>
</div>

<!--v-->

## Efficiency: time cost

<div style="text-align: left; margin-top: 0.5em;">
<img src="230505/time.png" width="100%" style="margin: 0 auto;">
</div>

d = 10 and d = 100

<!--v-->

## Effectiveness: Remove low value data

<div style="text-align: left; margin-top: 0.5em;">
<img src="230505/exp.png" width="100%" style="margin: 0 auto;">
</div>

<!--s-->

<div class="middle center">
<div style="width: 100%">

# Thanks

<hr/>

**Questions?**

</div>
</div>